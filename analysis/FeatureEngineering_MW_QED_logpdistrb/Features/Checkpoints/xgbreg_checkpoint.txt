# -*- coding: utf-8 -*-
"""xgbReg-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_orRXcQUVPwTjhQwntfC9_SVkJN8FcjC
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from xgboost import XGBRegressor

from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import make_scorer, mean_squared_error, r2_score

import matplotlib.pyplot as plt

data = pd.read_csv('qm9_feature_data.csv')
X_train, X_test, y_train, y_test = train_test_split(
    data.iloc[:,:-1].values,
    data.iloc[:,-1].values
)

# kfolds = KFold(shuffle = True, random_state = 42)
scorer = make_scorer(mean_squared_error, greater_is_better = False)

xgb = XGBRegressor(objective = 'reg:squarederror')
param_grid = {'max_depth': range(3,11),
              'learning_rate': [1e-4, 0.001, 0.01, 0.1, 1],
              'n_estimators': range(500, 5000),
              'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]}
xgb = RandomizedSearchCV(xgb, param_grid, n_iter = 100,
                         cv = 3, scoring = scorer, refit = True,
                         n_jobs = 2, verbose = 2)
xgb.fit(X_train, y_train)
best_params = xgb.best_params_

xgb = XGBRegressor(objective = 'reg:squarederror',
                   n_jobs = 2)
xgb.set_params(**best_params)
xgb.fit(X_train, y_train)

y_pred = xgb.predict(X_test)

r2_score(y_test, y_pred)

plt.scatter(y_test, y_pred)

